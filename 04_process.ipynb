{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080ab782",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import collections\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_predict, LeaveOneGroupOut\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, f1_score, precision_score, recall_score,\n",
    "    classification_report, confusion_matrix, roc_auc_score\n",
    ")\n",
    "from sklearn.base import clone\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9b327e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(\n",
    "    model,\n",
    "    features_path: str,\n",
    "    labels_path: str,\n",
    "    label_name: str = \"Label\",\n",
    "    cv_strategy=None,\n",
    "    groups_path: str = None,\n",
    "    multi_class=\"ovr\"\n",
    "):\n",
    "    X = np.load(features_path)\n",
    "    y = np.load(labels_path)\n",
    "    groups = np.load(groups_path) if groups_path else None\n",
    "\n",
    "    if cv_strategy is None:\n",
    "        cv_strategy = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    is_logo = isinstance(cv_strategy, LeaveOneGroupOut)\n",
    "    average_mode = \"micro\" if is_logo else \"macro\"\n",
    "\n",
    "    accs, f1s, precs, recalls, aucs, names = [], [], [], [], [], []\n",
    "    all_y_true, all_y_pred, all_y_proba = [], [], []\n",
    "\n",
    "    print(\"Features Extracted from: \", features_path)\n",
    "    print(f\"\\n CV {cv_strategy.__class__.__name__} Evaluation for: {label_name} using {model.__class__.__name__}\")\n",
    "    print(\"-\" * 90)\n",
    "    print(f\"{'Fold/Group':<15}{'Acc':>8}{'F1':>8}{'Prec':>10}{'Recall':>10}{'AUROC':>10}\")\n",
    "    print(\"-\" * 90)\n",
    "\n",
    "    for i, (train_idx, val_idx) in enumerate(cv_strategy.split(X, y, groups=groups), 1):\n",
    "        X_train, X_val = X[train_idx], X[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]\n",
    "        group_val = groups[val_idx[0]] if groups is not None else i\n",
    "\n",
    "        supports_weight = \"class_weight\" in model.get_params().keys()\n",
    "        clf_params = model.get_params()\n",
    "        if supports_weight and clf_params.get(\"class_weight\", None) is None:\n",
    "            class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
    "            weight_dict = {cls: w for cls, w in zip(np.unique(y_train), class_weights)}\n",
    "            model.set_params(class_weight=weight_dict)\n",
    "\n",
    "        clf = clone(model)\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_val)\n",
    "\n",
    "        try:\n",
    "            y_proba = clf.predict_proba(X_val)\n",
    "        except:\n",
    "            y_proba = None\n",
    "\n",
    "        acc = accuracy_score(y_val, y_pred)\n",
    "        f1 = f1_score(y_val, y_pred, average=average_mode, zero_division=0)\n",
    "        prec = precision_score(y_val, y_pred, average=average_mode, zero_division=0)\n",
    "        rec = recall_score(y_val, y_pred, average=average_mode, zero_division=0)\n",
    "\n",
    "        accs.append(acc)\n",
    "        f1s.append(f1)\n",
    "        precs.append(prec)\n",
    "        recalls.append(rec)\n",
    "        names.append(group_val)\n",
    "\n",
    "        if y_proba is not None:\n",
    "            try:\n",
    "                if multi_class == \"ovr\" and y_proba.shape[1] > 2:\n",
    "                    auc = roc_auc_score(y_val, y_proba, multi_class=multi_class, average=\"macro\")\n",
    "                else:\n",
    "                    # Binary case\n",
    "                    if len(y_proba.shape) == 1:\n",
    "                        auc = roc_auc_score(y_val, y_proba)\n",
    "                    else:\n",
    "                        auc = roc_auc_score(y_val, y_proba[:, 1])\n",
    "            except:\n",
    "                auc = float('nan')\n",
    "                warnings.warn(\"AUROC not computed\")\n",
    "        else:\n",
    "            auc = float('nan')\n",
    "        aucs.append(auc)\n",
    "\n",
    "        all_y_true.extend(y_val)\n",
    "        all_y_pred.extend(y_pred)\n",
    "        if y_proba is not None:\n",
    "            if len(y_proba.shape) == 2 and y_proba.shape[1] > 1:\n",
    "                all_y_proba.extend(y_proba[:, 1])\n",
    "            else:\n",
    "                all_y_proba.extend(y_proba)\n",
    "\n",
    "        print(f\"{str(group_val):<15}{acc:.3f}{f1:>8.3f}{prec:>10.3f}{rec:>10.3f}{auc:>10.3f}\")\n",
    "\n",
    "        if not is_logo or (i <= 5):\n",
    "            cm = confusion_matrix(y_val, y_pred)\n",
    "            disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "            disp.plot(cmap=plt.cm.Blues)\n",
    "            plt.title(f\"Confusion Matrix for Fold/Group {group_val}\")\n",
    "            plt.show()\n",
    "\n",
    "    print(\"\\n Average:\")\n",
    "    print(f\"  Accuracy  = {np.mean(accs):.3f}\")\n",
    "    print(f\"  Precision = {np.mean(precs):.3f}\")\n",
    "    print(f\"  Recall    = {np.mean(recalls):.3f}\")\n",
    "    print(f\"  {average_mode.title()}-F1 = {np.mean(f1s):.3f}\")\n",
    "    print(f\"  AUROC     = {np.nanmean(aucs):.3f}\")\n",
    "\n",
    "    if is_logo:\n",
    "        print(\"\\n Global Evaluation (LOGO):\")\n",
    "        global_acc = accuracy_score(all_y_true, all_y_pred)\n",
    "        global_f1 = f1_score(all_y_true, all_y_pred, average=\"macro\", zero_division=0)\n",
    "        global_rec = recall_score(all_y_true, all_y_pred, average=\"macro\", zero_division=0)\n",
    "        global_prec = precision_score(all_y_true, all_y_pred, average=\"macro\", zero_division=0)\n",
    "\n",
    "        try:\n",
    "            global_auc = roc_auc_score(all_y_true, all_y_proba)\n",
    "        except:\n",
    "            global_auc = float('nan')\n",
    "\n",
    "        print(f\"  Accuracy  = {global_acc:.3f}\")\n",
    "        print(f\"  Precision = {global_prec:.3f}\")\n",
    "        print(f\"  Recall    = {global_rec:.3f}\")\n",
    "        print(f\"  Macro-F1  = {global_f1:.3f}\")\n",
    "        print(f\"  AUROC     = {global_auc:.3f}\")\n",
    "\n",
    "    result_df = pd.DataFrame({\n",
    "        \"Fold_or_Group\": names,\n",
    "        \"Accuracy\": accs,\n",
    "        \"Precision\": precs,\n",
    "        \"Recall\": recalls,\n",
    "        f\"{average_mode.title()}-F1\": f1s,\n",
    "        \"AUROC\": aucs\n",
    "    })\n",
    "\n",
    "    return result_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edef12e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLPClassifier(\n",
    "    hidden_layer_sizes=(128,),\n",
    "    random_state=42,\n",
    "    max_iter=500,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f265941",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"path/to/features\"\n",
    "feature_path = f\"{base_dir}/features/features_swin.npy\"\n",
    "label_path = f\"{base_dir}/features/labels_callback_binary.npy\"\n",
    "group_path = f\"{base_dir}/features/labels_patient_id.npy\"\n",
    "\n",
    "# ==== Load data ====\n",
    "X = np.load(feature_path)\n",
    "y = np.load(label_path)\n",
    "groups = np.load(group_path)\n",
    "\n",
    "# ==== Only get patients who has at least 3 images, not greater than 120 patients ====\n",
    "unique_ids, counts = np.unique(groups, return_counts=True)\n",
    "valid_patients = unique_ids[counts >= 3][:120]\n",
    "mask = np.isin(groups, valid_patients)\n",
    "\n",
    "# ==== Apply mask filter ====\n",
    "X_filtered = X[mask]\n",
    "y_filtered = y[mask]\n",
    "groups_filtered = groups[mask]\n",
    "\n",
    "# ==== Save files ====\n",
    "np.save(\"nonp/filtered_features.npy\", X_filtered)\n",
    "np.save(\"nonp/filtered_labels.npy\", y_filtered)\n",
    "np.save(\"nonp/filtered_groups.npy\", groups_filtered)\n",
    "\n",
    "# ==== Cross Validation ====\n",
    "logo = LeaveOneGroupOut()\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d355961",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation(model=model,\n",
    "           features_path=feature_path,\n",
    "           labels_path=label_path,\n",
    "           label_name=\"Callback (Binary) - KFold\",\n",
    "           cv_strategy=kfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c94957",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation(\n",
    "    model=model,\n",
    "    features_path=\"nonp/filtered_features.npy\",\n",
    "    labels_path=\"nonp/filtered_labels.npy\",\n",
    "    label_name=\"Callback (Binary) - LOGO\",\n",
    "    cv_strategy=logo,\n",
    "    groups_path=\"nonp/filtered_groups.npy\",\n",
    "    multi_class=\"raise\"  # binary\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
